{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyshark\n",
    "import glob, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "\n",
    "devices_devicenames = ['August1', 'August2', 'Door1', 'Door2', 'Energy1', 'Energy2', 'Kevo', 'Push', 'Room1', 'Room2', 'Weather']\n",
    "devices_publicaddrs = ['Home1', 'Home2']\n",
    "\n",
    "id_devicenames = [['Kevo','Unikey'],\n",
    "                'Eve Door 91B3',\n",
    "                'Eve Door DC42',\n",
    "                's',\n",
    "                'Aug',\n",
    "                'L402EL4',\n",
    "                'Eve Energy 51C0',\n",
    "                'Eve Energy 556E',\n",
    "                'Eve Weather 943D',\n",
    "                'Eve Room 8F24',\n",
    "                'Eve Room 4A04']\n",
    "\n",
    "BLE_DEVICES = sorted(devices_devicenames + devices_publicaddrs)\n",
    "\n",
    "# Devices that can be identified using public (static) advertising addresses\n",
    "DEVICES_PUBLICADDRS = {'ec:fe:7e:14:44:be' : 'Home1', \n",
    "                       'ec:fe:7e:14:44:a1' : 'Home2'}\n",
    "\n",
    "# Devices that can be identified using device names\n",
    "DEVICES_NAMES = {'August1': 'L402EL4',\n",
    "                'August2': 'Aug',\n",
    "                'Door1': 'Eve Door 91B3',\n",
    "                'Door2': 'Eve Door DC42',\n",
    "                'Energy1': 'Eve Energy 556E',\n",
    "                'Energy2': 'Eve Energy 51C0',\n",
    "                'Kevo': ['Kevo', 'Unikey'],\n",
    "                'Push': 's',\n",
    "                'Room1': 'Eve Room 4A04',\n",
    "                'Room2': 'Eve Room 8F24',\n",
    "                'Weather': 'Eve Weather 943D'}\n",
    "\n",
    "# Just the reverse of DEVICES_NAMES\n",
    "NAMES_DEVICES = {'Aug': 'August2',\n",
    "                 'Eve Door 91B3': 'Door1',\n",
    "                 'Eve Door DC42': 'Door2',\n",
    "                 'Eve Energy 51C0': 'Energy2',\n",
    "                 'Eve Energy 556E': 'Energy1',\n",
    "                 'Eve Room 4A04': 'Room1',\n",
    "                 'Eve Room 8F24': 'Room2',\n",
    "                 'Eve Weather 943D': 'Weather',\n",
    "                 'Kevo': 'Kevo',\n",
    "                 'L402EL4': 'August1',\n",
    "                 'Unikey': 'Kevo',\n",
    "                 's': 'Push'}\n",
    "\n",
    "DEVICE_TYPE = {'August1': 'lock',\n",
    "                'August2': 'lock',\n",
    "                'Door1': 'door',\n",
    "                'Door2': 'door',\n",
    "                'Energy1': 'plug',\n",
    "                'Energy2': 'plug',\n",
    "                'Home1': 'door',\n",
    "                'Home2': 'door',\n",
    "                'Kevo': 'lock',\n",
    "                'Push': 'temp',\n",
    "                'Room1': 'temp',\n",
    "                'Room2': 'temp',\n",
    "                'Weather': 'temp'}\n",
    "\n",
    "TRAINING_TEST = {'August1': 'train',\n",
    "                 'August2': 'test',\n",
    "                 'Door1': 'train',\n",
    "                 'Door2': 'test',\n",
    "                 'Energy1': 'train',\n",
    "                 'Energy2': 'train',\n",
    "                 'Home1': 'train',\n",
    "                 'Home2': 'train',\n",
    "                 'Kevo': 'train',\n",
    "                 'Push': 'train',\n",
    "                 'Room1': 'train',\n",
    "                 'Room2': 'test',\n",
    "                 'Weather': 'train'}\n",
    "\n",
    "PDU_TYPES = {0: 'ADV_IND',\n",
    "             1: 'ADV_DIRECT_IND',\n",
    "             2: 'ADV_NONCONN_IND',\n",
    "             3: 'SCAN_REQ',\n",
    "             4: 'SCAN_RSP',\n",
    "             5: 'CONNECT_REQ',\n",
    "             6: 'ADV_SCAN_IND'}\n",
    "\n",
    "SRC_DIR = './BLE_Source/'\n",
    "DST_DIR = './BLE_Destination/'\n",
    "PCAP_DIR = '/root/Documents/Thesis/BLE_PCAPS/'\n",
    "TIMING_PKT_NUMBER = 25000\n",
    "\n",
    "FEATURES = ['Name', 'DeviceName', 'AccessAddr', 'AdvertAddr', 'BLE_LL_Length', 'PDUTypeNum', 'TxAddr', 'CompanyID','ScanAddr',\n",
    "           'RFChannel', 'PacketLength', 'Time']\n",
    "\n",
    "path_name = os.getcwd()\n",
    "DATE = path_name[path_name.rindex('/')+1:]\n",
    "PROC_TIME = \"ble_processing_time_\" + DATE + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_assoc_pkts(df, device):\n",
    "    \"\"\"\n",
    "    Gets the count of packets of a given device that are sent within a second of each other (associated packets)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: (dataframe) the dataframe containing the packet information\n",
    "    device: (string) the name of the device for which the assoc_pkt count will be calculated\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    assoc_count: (pandas series) contains the assoc_packet count for each packet. \n",
    "                Uses the index of the packet from the dataframe\n",
    "    \"\"\"\n",
    "        \n",
    "    ASSOC_PKT_THRESHOLD = 1 # the threshold in seconds within which a packet will be considered an assoc_pkt\n",
    "\n",
    "    # Extract time values of all packets belonging to a certain device\n",
    "    df_device = df[df[\"Name\"]==device]\n",
    "    pkt_time_values = np.array(df_device[\"Time\"].values)\n",
    "    \n",
    "    assoc_pkt_counts = []\n",
    "    \n",
    "    # Iterate through each packet of the device\n",
    "    for pkt_index in range(0,len(df_device)):  \n",
    "\n",
    "        # Create an array of size=len(pkt_time_values) that contains the time value of packet X\n",
    "        pkt_time = np.full((len(pkt_time_values),),df_device.iloc[pkt_index][\"Time\"])\n",
    "\n",
    "        # Calculate the time difference between packet X and all other packets\n",
    "        diff = np.abs(np.subtract(pkt_time, pkt_time_values))\n",
    "\n",
    "        # Calculate the count of packets that would be considered an assoc_pkt based on ASSOC_PKT_THRESHOLD\n",
    "        assoc_pkts = (diff <= ASSOC_PKT_THRESHOLD).sum()\n",
    "        assoc_pkt_counts.append(assoc_pkts)\n",
    "        \n",
    "    \n",
    "    assoc_count = pd.Series(assoc_pkt_counts, index=df_device.index)\n",
    "    return assoc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(path='/root/Documents/Thesis/Code/BLE_Source'):\n",
    "    \"\"\"\n",
    "    Unit that takes all the csv files produced by the feature_extractor unit and puts them into a pandas dataframe.\n",
    "    Returns a clean dataframe with all good data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: (filesystem) the absolute path of the folder containing the csv files\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    none\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe: (pandas dataframe) a useful data structure for machine learning\n",
    "    counts: (pandas series) packet counts for each device \n",
    "    \"\"\"\n",
    "    \n",
    "    # Search the path for csv files\n",
    "    all_csvs = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "    # Collect all csvs in one dataframe\n",
    "    df_from_each_file = (pd.read_csv(f) for f in all_csvs)\n",
    "    df = pd.concat(df_from_each_file, ignore_index=True, sort=False)\n",
    "\n",
    "    # Add device type of each packet\n",
    "    df[\"DeviceType\"] = df[\"Name\"].map(DEVICE_TYPE)\n",
    "        \n",
    "    # Add whether device is a training or test device\n",
    "    df[\"Set\"] = df[\"Name\"].map(TRAINING_TEST)\n",
    "    \n",
    "    # One-hot encode device type (response variable)\n",
    "    deviceType_series = pd.get_dummies(df[\"DeviceType\"])\n",
    "    df = pd.concat([df, deviceType_series], axis=1)\n",
    "    \n",
    "    # TODO: One-hot encode company ID \n",
    "    \n",
    "    # One-hot encode PDU_type\n",
    "    df[\"PDUType\"] = df[\"PDUTypeNum\"].map(PDU_TYPES)\n",
    "    pduType_series = pd.get_dummies(df[\"PDUType\"])\n",
    "    df = pd.concat([df, pduType_series], axis=1)\n",
    "    \n",
    "    # Get number of associated packets for each packet\n",
    "    list_assoc_pkts = []\n",
    "#     for device in list(df[\"Name\"].unique()):\n",
    "    for device in BLE_DEVICES:\n",
    "        assoc_pkts = count_assoc_pkts(df, device)\n",
    "        list_assoc_pkts.append(assoc_pkts)\n",
    "    df[\"Assoc_Packets\"] = pd.concat(list_assoc_pkts)\n",
    "    \n",
    "    # Fill NaNs with 0\n",
    "    df[\"CompanyID\"].fillna\n",
    "    \n",
    "    # Count packets for each device\n",
    "    device_counts = df[\"Name\"].value_counts()\n",
    "    print device_counts\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = pyshark.FileCapture('/root/Documents/Thesis/PCAPS/master.cap', only_summaries=False)\n",
    "cap = pyshark.FileCapture('/root/Documents/Thesis/BLE_PCAPS/home1home2-15min.pcap')\n",
    "\n",
    "SCAN_RSP = '4'\n",
    "s_adv_addr = 'd8:10:ed:43:60:ac'\n",
    "\n",
    "DEVICES_PUBLICADDRS = {'ec:fe:7e:14:44:be' : 'Home1', \n",
    "                       'ec:fe:7e:14:44:a1' : 'Home2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August2    10466\n",
      "Energy1     4396\n",
      "Energy2     3997\n",
      "Home1       3099\n",
      "Home2       3095\n",
      "August1     1819\n",
      "Push        1529\n",
      "Kevo        1230\n",
      "Door1        520\n",
      "Door2        453\n",
      "Weather      414\n",
      "Room1        342\n",
      "Room2        272\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = make_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0        13755\n",
       "465.0      12219\n",
       "133.0       4068\n",
       "46966.0     1207\n",
       "51062.0      208\n",
       "46967.0      112\n",
       "449.0         16\n",
       "209.0         16\n",
       "8657.0        11\n",
       "2513.0         4\n",
       "8837.0         2\n",
       "33233.0        2\n",
       "149.0          2\n",
       "49014.0        2\n",
       "389.0          1\n",
       "8401.0         1\n",
       "467.0          1\n",
       "193.0          1\n",
       "977.0          1\n",
       "18053.0        1\n",
       "9041.0         1\n",
       "9429.0         1\n",
       "Name: CompanyID, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CompanyID\"] = df[\"CompanyID\"].fillna(0)\n",
    "df[\"CompanyID\"].value_counts()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
