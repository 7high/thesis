{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, datetime, getopt, glob, itertools, logging, os, sys, time\n",
    "import helpers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyshark\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "ROUTER = '78:d2:94:4d:ab:3e'\n",
    "WIFI_DEVICES = ['ec:1a:59:e4:fd:41', 'ec:1a:59:e4:fa:09',\n",
    "                'ec:1a:59:e5:02:0d', '14:91:82:24:dd:35',\n",
    "                '60:38:e0:ee:7c:e5', '14:91:82:cd:df:3d',\n",
    "                'b4:75:0e:0d:94:65', 'b4:75:0e:0d:33:d5',\n",
    "                '94:10:3e:2b:7a:55', '30:8c:fb:3a:1a:ad',\n",
    "                'd0:73:d5:26:b8:4c', 'd0:73:d5:26:c9:27',\n",
    "                'ac:84:c6:97:7c:cc', 'b0:4e:26:c5:2a:41',\n",
    "                '70:4f:57:f9:e1:b8', ROUTER]\n",
    "\n",
    "DEVICE_NAME = {'ec:1a:59:e4:fd:41' : 'Netcam1', \n",
    "               'ec:1a:59:e4:fa:09' : 'Netcam2',\n",
    "               'ec:1a:59:e5:02:0d' : 'Netcam3',\n",
    "               '14:91:82:24:dd:35' : 'Insight',\n",
    "               '60:38:e0:ee:7c:e5' : 'Mini',\n",
    "               '14:91:82:cd:df:3d' : 'Switch1',\n",
    "               'b4:75:0e:0d:94:65' : 'Switch2',\n",
    "               'b4:75:0e:0d:33:d5' : 'Switch3',\n",
    "               '94:10:3e:2b:7a:55' : 'Switch4',\n",
    "               '30:8c:fb:3a:1a:ad' : 'Dropcam',\n",
    "               'd0:73:d5:26:b8:4c' : 'Lifx1', \n",
    "               'd0:73:d5:26:c9:27' : 'Lifx2',\n",
    "               'ac:84:c6:97:7c:cc' : 'Kasa', \n",
    "               'b0:4e:26:c5:2a:41' : 'TpBulb',\n",
    "               '70:4f:57:f9:e1:b8' : 'TpPlug',\n",
    "                ROUTER : 'Router'}\n",
    "\n",
    "DEVICE_TYPE = {'ec:1a:59:e4:fd:41' : 'camera',\n",
    "               'ec:1a:59:e4:fa:09' : 'camera',\n",
    "               'ec:1a:59:e5:02:0d' : 'camera',\n",
    "               '14:91:82:24:dd:35' : 'plug',\n",
    "               '60:38:e0:ee:7c:e5' : 'plug',\n",
    "               '14:91:82:cd:df:3d' : 'plug',\n",
    "               'b4:75:0e:0d:94:65' : 'plug',\n",
    "               'b4:75:0e:0d:33:d5' : 'plug',\n",
    "               '94:10:3e:2b:7a:55' : 'plug',\n",
    "               '30:8c:fb:3a:1a:ad' : 'camera',\n",
    "               'd0:73:d5:26:b8:4c' : 'bulb', \n",
    "               'd0:73:d5:26:c9:27' : 'bulb',\n",
    "               'ac:84:c6:97:7c:cc' : 'camera', \n",
    "               'b0:4e:26:c5:2a:41' : 'bulb',\n",
    "               '70:4f:57:f9:e1:b8' : 'plug',\n",
    "                ROUTER : 'router'}\n",
    "\n",
    "TRAINING_TEST = {'ec:1a:59:e4:fd:41' : 'train', \n",
    "                 'ec:1a:59:e4:fa:09' : 'train',\n",
    "                 'ec:1a:59:e5:02:0d' : 'test',\n",
    "                 '14:91:82:24:dd:35' : 'train',\n",
    "                 '60:38:e0:ee:7c:e5' : 'train',\n",
    "                 '14:91:82:cd:df:3d' : 'train',\n",
    "                 'b4:75:0e:0d:94:65' : 'train',\n",
    "                 'b4:75:0e:0d:33:d5' : 'train',\n",
    "                 '94:10:3e:2b:7a:55' : 'test',\n",
    "                 '30:8c:fb:3a:1a:ad' : 'train',\n",
    "                 'd0:73:d5:26:b8:4c' : 'train', \n",
    "                 'd0:73:d5:26:c9:27' : 'test',\n",
    "                 'ac:84:c6:97:7c:cc' : 'test', \n",
    "                 'b0:4e:26:c5:2a:41' : 'train',\n",
    "                 '70:4f:57:f9:e1:b8' : 'test'}\n",
    "\n",
    "DATA_PKT_SUBTYPES = {32 : 'Data',\n",
    "                     40 : 'QoS_Data',\n",
    "                     44 : 'QoS_Null'}\n",
    "\n",
    "FEATURES = [\"Time\", \"PacketLength\", \"Duration\", \"SourceAddr\", \"DestAddr\", \"SubtypeNum\"]\n",
    "SRC_DIR = './Source/'\n",
    "DST_DIR = './Destination/'\n",
    "PCAP_DIR = '/root/Documents/Thesis/PCAPS'\n",
    "TIMING_PKT_NUMBER = 25000\n",
    "DATA_FRAME_TYPE = '2'\n",
    "\n",
    "path_name = os.getcwd()\n",
    "DATE = path_name[path_name.rindex('/')+1:]\n",
    "PROC_TIME = \"wifi_processing_time_\" + DATE + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_packet(pkt, tgt_files_by_src):\n",
    "    \"\"\"\n",
    "    Parses a given packet and extracts the following features:\n",
    "        - destination MAC address\n",
    "        - source MAC address\n",
    "        - time of transmission\n",
    "        - packet length\n",
    "        \n",
    "    The features of the packet are written out to a csv row, which is\n",
    "    in turn written out to a csv file in the given dictionaries.\n",
    "    \n",
    "    This code is heavily based on code written by Capt Steven Beyer.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pkt: (Pyshark packet object) the packet from which features will be extracted\n",
    "    tgt_files_by_src: (dictionary) a dictionary of open csv files.\n",
    "        The keys are device source addresses, and the values are the open csv files.\n",
    "    tgt_files_by_dst: (dictionary) a dictionary of open csv files.\n",
    "        The keys are device destination addresses, and the values are the open csv files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pkt_dst = pkt.wlan.da\n",
    "        pkt_src = pkt.wlan.sa\n",
    "        \n",
    "#         if (pkt_src in WIFI_DEVICES) and (pkt_dst in WIFI_DEVICES):\n",
    "        if (pkt_src in WIFI_DEVICES):\n",
    "            # Extract features\n",
    "            pkt_time = pkt.frame_info.time_epoch\n",
    "            pkt_len = pkt.length\n",
    "            pkt_duration = pkt.wlan.duration\n",
    "            pkt_subtype_num = pkt.wlan.fc_type_subtype\n",
    "            \n",
    "            # Output matches FEATURES\n",
    "            output = [pkt_time, pkt_len, pkt_duration, pkt_src, pkt_dst, pkt_subtype_num]\n",
    "            \n",
    "            csv.writer(tgt_files_by_src[pkt_src]).writerow(output)            \n",
    "    \n",
    "    except AttributeError:\n",
    "        print \"ignored: \", pkt.number            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mac_vendors():\n",
    "    \"\"\"\n",
    "    Uses the macvendors.co API to lookup the vendors of Wi-Fi devices.\n",
    "    Requires internet access.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    device_vendors (dict): keys(str) = WIFI_DEVICES MAC addresses, values(str) = vendor names\n",
    "    \"\"\"\n",
    "    import json, requests\n",
    "\n",
    "    # Get JSON response from API\n",
    "    vendors_json = []\n",
    "    for addr in WIFI_DEVICES:\n",
    "        response = requests.get('http://macvendors.co/api/' + addr).text\n",
    "        vendors_json.append(response)\n",
    "\n",
    "    # Extracting company from API response\n",
    "    vendors = []\n",
    "    for vendor_json in vendors_json:\n",
    "        response = json.loads(vendor_json)\n",
    "        company = str(response['result']['company']).split(' ',1)[0].capitalize()\n",
    "        vendors.append(company)\n",
    "\n",
    "    # Put device MAC addresses and vendors into dictionary\n",
    "    device_vendors = dict(zip(WIFI_DEVICES, vendors))\n",
    "    \n",
    "    return device_vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_assoc_pkts(df, device):\n",
    "    \"\"\"\n",
    "    Gets the count of packets of a given device that are sent within a second of each other (associated packets)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: (dataframe) the dataframe containing the packet information\n",
    "    device: (string) the name of the device for which the assoc_pkt count will be calculated\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    assoc_count: (pandas series) contains the assoc_packet count for each packet. \n",
    "                Uses the index of the packet from the dataframe\n",
    "    \"\"\"\n",
    "        \n",
    "    ASSOC_PKT_THRESHOLD = 1 # the threshold in seconds within which a packet will be considered an assoc_pkt\n",
    "\n",
    "    # Extract time values of all packets belonging to a certain device\n",
    "    df_device = df[df[\"Name\"]==device]\n",
    "    pkt_time_values = np.array(df_device[\"Time\"].values)\n",
    "    \n",
    "    assoc_pkt_counts = []\n",
    "    \n",
    "    # Iterate through each packet of the device\n",
    "    for pkt_index in range(0,len(df_device)):  \n",
    "\n",
    "        # Create an array of size=len(pkt_time_values) that contains the time value of packet X\n",
    "        pkt_time = np.full((len(pkt_time_values),),df_device.iloc[pkt_index][\"Time\"])\n",
    "\n",
    "        # Calculate the time difference between packet X and all other packets\n",
    "        diff = np.abs(np.subtract(pkt_time, pkt_time_values))\n",
    "\n",
    "        # Calculate the count of packets that would be considered an assoc_pkt based on ASSOC_PKT_THRESHOLD\n",
    "        assoc_pkts = (diff <= ASSOC_PKT_THRESHOLD).sum()\n",
    "        assoc_pkt_counts.append(assoc_pkts)\n",
    "        \n",
    "    \n",
    "    assoc_count = pd.Series(assoc_pkt_counts, index=df_device.index)\n",
    "    return assoc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wifi_extract_packet_features(filename = os.path.join(PCAP_DIR, 'master.cap'), create_master=True):\n",
    "    \"\"\"\n",
    "    Unit that extracts wanted features out of packets in a packet capture file.\n",
    "    The feature_extractor focuses on features derived from packet information. \n",
    "    Secondary features are processed by the make_dataframe function.\n",
    "    Produces two csv files for each device in WIFI_DEVICES (see Global Variables).\n",
    "    One file is for all packets where the device is the source; the other is where the device is the destination.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: (string) the absolute path of the packet capture file\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    Source directory: (filesystem) creates a directory containing csv files for each device \n",
    "        where it is the source of the packet\n",
    "    Destination directory: (filesystem) creates a directory containing csv files for each device \n",
    "        where it is the destination of the packet\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    none\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare writers\n",
    "    pt_file = open(PROC_TIME, 'w')\n",
    "    csv.writer(pt_file).writerow([\"Unit\", \"Total Packets Processed\", \"Total Process Time\", \"Average Process Time\"])\n",
    "    pt_file.close()\n",
    "\n",
    "    # Initialize counters\n",
    "    pkt_count = 0\n",
    "    total_time_processing = 0\n",
    "    total_time_start = time.time()\n",
    "\n",
    "    # Initialize dicts for each device\n",
    "    tgt_files_by_src = {}\n",
    "    \n",
    "    # Combine all pcaps in directory in one master pcap\n",
    "    if (create_master):\n",
    "        try:\n",
    "            if os.path.exists(\"/root/Documents/Thesis/PCAPS/master.cap\"):\n",
    "                os.remove(\"/root/Documents/Thesis/PCAPS/master.cap\")\n",
    "                \n",
    "            ret = os.system('mergecap /root/Documents/Thesis/PCAPS/wifi* -w /root/Documents/Thesis/PCAPS/master.cap')\n",
    "            if ret != 0:\n",
    "                raise OSError\n",
    "        except OSError:\n",
    "            print 'Could not make master capture file'\n",
    "\n",
    "    # Initialize capture file \n",
    "    cap = pyshark.FileCapture(filename, only_summaries=False)\n",
    "\n",
    "    # Get time of first packet\n",
    "    prev_pkt_time = cap[0].frame_info.time_epoch\n",
    "\n",
    "    # Initialize output folders\n",
    "    helpers.init_dirs('wifi')\n",
    "    \n",
    "    # Open output files for each Wi-Fi device\n",
    "    for device in WIFI_DEVICES:\n",
    "        tgt_files_by_src[device] = open(SRC_DIR + device.replace(':', '.') + \".csv\", 'a')\n",
    "        \n",
    "        # Initialize with column headers\n",
    "        csv.writer(tgt_files_by_src[device]).writerow(FEATURES)\n",
    "    \n",
    "    # Go through each packet in capture, and store pertinent packets to csv files\n",
    "    for pkt in cap:\n",
    "        if pkt_count % TIMING_PKT_NUMBER == 0:\n",
    "            print \"Working packet #\", pkt_count, \"...\"\n",
    "        pkt_count += 1\n",
    "\n",
    "        time_start_singlepacket = time.time()\n",
    "        if pkt.wlan.fc_type == DATA_FRAME_TYPE:\n",
    "            parse_packet(pkt, tgt_files_by_src)\n",
    "            total_time_processing += time.time() - time_start_singlepacket\n",
    "\n",
    "    total_time_elapsed = time.time() - total_time_start\n",
    "    \n",
    "    # Close files\n",
    "    for open_file in tgt_files_by_src.values():\n",
    "        open_file.close()\n",
    "        \n",
    "    # Rename files to device names for readability\n",
    "    helpers.rename_csv_files(DEVICE_NAME)\n",
    "        \n",
    "    # Calculate time variables\n",
    "    final_time = time.time()\n",
    "    normalized_total_time = (TIMING_PKT_NUMBER * total_time_elapsed) / pkt_count\n",
    "    normalized_processing_time = (TIMING_PKT_NUMBER * total_time_processing) / pkt_count\n",
    "\n",
    "    # Print time variables\n",
    "    print \"Total number of packets processed: \", pkt_count\n",
    "    print \"Total data processing time: \", total_time_elapsed\n",
    "    print \"Normalized total processing time per 25k packets: \", normalized_total_time\n",
    "    print \"Total capture file processing time: \", total_time_processing\n",
    "    print \"Normalized capture file processing time: \", normalized_processing_time\n",
    "\n",
    "    # Print out time metrics to csv\n",
    "    pt_file = open(PROC_TIME, 'a')\n",
    "    csv.writer(pt_file).writerow([\"Packet capture iteration\", pkt_count, total_time_processing, normalized_processing_time])\n",
    "    csv.writer(pt_file).writerow([\"Component start and finish time\", total_time_start, final_time, final_time-total_time_start])\n",
    "    pt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_dataframe(path='/root/Documents/Thesis/Code/Source'):\n",
    "    \"\"\"\n",
    "    Unit that takes all the csv files produced by the feature_extractor unit and puts them into a pandas dataframe.\n",
    "    Returns a clean dataframe with all good data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: (filesystem) the absolute path of the folder containing the csv files\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    none\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe: (pandas dataframe) a useful data structure for machine learning\n",
    "    counts: (pandas series) packet counts for each device \n",
    "    \"\"\"\n",
    "    \n",
    "    # Search the path for csv files\n",
    "#     path='/root/Documents/Thesis/Code/Source'\n",
    "    all_csvs = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "    # Collect all csvs in one dataframe\n",
    "    df_from_each_file = (pd.read_csv(f) for f in all_csvs)\n",
    "    df = pd.concat(df_from_each_file, ignore_index=True, sort=False)\n",
    "\n",
    "    # Add device type, device ID of each packet\n",
    "    df[\"DeviceType\"] = df[\"SourceAddr\"].map(DEVICE_TYPE)\n",
    "    df[\"Name\"] = df[\"SourceAddr\"].map(DEVICE_NAME)\n",
    "    \n",
    "    # Add whether device is a training or test device\n",
    "    df[\"Set\"] = df[\"SourceAddr\"].map(TRAINING_TEST)\n",
    "    \n",
    "    # One-hot encode device type (response variable)\n",
    "    deviceType_series = pd.get_dummies(df[\"DeviceType\"])\n",
    "    df = pd.concat([df, deviceType_series], axis=1)\n",
    "    \n",
    "    # One-hot encode MAC vendors\n",
    "    df[\"Vendor\"] = df[\"SourceAddr\"].map(get_mac_vendors())\n",
    "    vendor_series = pd.get_dummies(df[\"Vendor\"])\n",
    "    df = pd.concat([df, vendor_series], axis=1)\n",
    "\n",
    "    # One-hot encode packet subtype\n",
    "    df[\"Subtype\"] = df[\"SubtypeNum\"].map(DATA_PKT_SUBTYPES)\n",
    "    subtype_series = pd.get_dummies(df[\"Subtype\"])\n",
    "    df = pd.concat([df, subtype_series], axis=1)   \n",
    "    \n",
    "    # Get number of associated packets for each packet\n",
    "    list_assoc_pkts = []\n",
    "    \n",
    "#     for device in list(df[\"Name\"].unique()):\n",
    "    for device in DEVICE_NAME.values():\n",
    "        assoc_pkts = count_assoc_pkts(df, device)\n",
    "        list_assoc_pkts.append(assoc_pkts)\n",
    "    df[\"Assoc_Packets\"] = pd.concat(list_assoc_pkts)\n",
    "    \n",
    "    # Count packets for each device\n",
    "    device_counts = df[\"Name\"].value_counts()\n",
    "    print device_counts\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    randomforest = RandomForestClassifier(random_state=0, n_jobs=2)\n",
    "    rf_model = randomforest.fit(X_train, y_train)\n",
    "\n",
    "    preds = rf_model.predict(X_test)\n",
    "    score = rf_model.score(X_test, y_test)\n",
    "    \n",
    "#     print_confusion_matrix()\n",
    "    \n",
    "    time_elapsed = time.time() - time_start\n",
    "    return {'Score' : score, 'Time' : time_elapsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbors_classifier(X_train, y_train, X_test, y_test):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=5, n_jobs=2)\n",
    "    knn_model = knn.fit(X_train, y_train)\n",
    "    \n",
    "    preds = knn_model.predict(X_test)\n",
    "    score = knn_model.score(X_test, y_test)\n",
    "    \n",
    "#     print_confusion_matrix()\n",
    "    \n",
    "    time_elapsed = time.time() - time_start\n",
    "    return {'Score' : score, 'Time' : time_elapsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_classifier(X_train, y_train, X_test, y_test):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda_model = lda.fit(X_train, y_train)\n",
    "    \n",
    "    preds = lda_model.predict(X_test)\n",
    "    score = lda_model.score(X_test, y_test)\n",
    "    \n",
    "#     print_confusion_matrix()\n",
    "\n",
    "    time_elapsed = time.time() - time_start\n",
    "    return {'Score' : score, 'Time' : time_elapsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all_classify(df, features_list, y_list):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    # Divide df by train and test devices\n",
    "    df_test = df[df[\"Set\"]==\"test\"]\n",
    "    df_train = df[df[\"Set\"]==\"train\"]\n",
    "    \n",
    "    # Train using chosen features\n",
    "    X_train = df_train[features_list]\n",
    "    X_test = df_test[features_list]\n",
    "\n",
    "    for device_type in y_list:\n",
    "        # Set one device type as y\n",
    "        y_train = df_train[device_type]\n",
    "        y_test = df_test[device_type]\n",
    "\n",
    "        time_start_clf = time.time()\n",
    "\n",
    "        rf_clf = random_forest_classifier(X_train, y_train, X_test, y_test)\n",
    "        knn_clf = k_neighbors_classifier(X_train, y_train, X_test, y_test)\n",
    "        lda_clf = lda_classifier(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        time_elapsed_clf = time.time() - time_start_clf\n",
    "\n",
    "        print \"Device Type:\", device_type\n",
    "        print \"Random Forest Score:\", rf_clf['Score'], \"Time: \", rf_clf['Time']\n",
    "        print \"KNN Score:\", knn_clf['Score'], \"Time: \", knn_clf['Time']\n",
    "        print \"LDA Score:\", lda_clf['Score'], \"Time: \", lda_clf['Time']\n",
    "        print \"Total time (classifiers):\", time_elapsed_clf\n",
    "        print \"\"\n",
    "    \n",
    "    print \"Total time (one vs all_classify):\", time.time() - time_start\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_one_classify(df, features_list, y_list):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    # Get possible combinations for one vs one\n",
    "    combinations = [combination for combination in itertools.combinations(y_list, 2)]\n",
    "\n",
    "    for device_pair in combinations:\n",
    "        # Only use data with the two device types needed for one vs one classification\n",
    "        pos_device_type = device_pair[0]\n",
    "        neg_device_type = device_pair[1]\n",
    "        df_1v1 = df[(df[\"DeviceType\"]==pos_device_type) | (df[\"DeviceType\"]==neg_device_type)]\n",
    "\n",
    "        # Separate df into train and test sets\n",
    "        df_train = df_1v1[df_1v1[\"Set\"]==\"train\"]\n",
    "        df_test = df_1v1[df_1v1[\"Set\"]==\"test\"]\n",
    "        X_train = df_train[features_list]\n",
    "        X_test = df_test[features_list]\n",
    "        y_train = df_train[pos_device_type]\n",
    "        y_test = df_test[pos_device_type]\n",
    "        \n",
    "        time_start_clf = time.time()\n",
    "\n",
    "        rf_clf = random_forest_classifier(X_train, y_train, X_test, y_test)\n",
    "        knn_clf = k_neighbors_classifier(X_train, y_train, X_test, y_test)\n",
    "        lda_clf = lda_classifier(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        time_elapsed_clf = time.time() - time_start_clf\n",
    "\n",
    "        print \"Device Pair:\", device_pair\n",
    "        print \"Random Forest Score:\", rf_clf['Score'], \"Time: \", rf_clf['Time']\n",
    "        print \"KNN Score:\", knn_clf['Score'], \"Time: \", knn_clf['Time']\n",
    "        print \"LDA Score:\", lda_clf['Score'], \"Time: \", lda_clf['Time']\n",
    "        print \"Total time (classifiers):\", time_elapsed_clf\n",
    "        print \"\"\n",
    "    \n",
    "    print \"Total time (one vs one_classify):\", time.time() - time_start\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix():\n",
    "    return \"print_confusion_matrix goes here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old ./Source deleted\n",
      "Old ./Destination deleted\n",
      "Total number of packets processed:  1375941\n",
      "Total data processing time:  1651.73450613\n",
      "Normalized total processing time per 25k packets:  30.0109980393\n",
      "Total capture file processing time:  159.951148272\n",
      "Normalized capture file processing time:  2.90621378881\n"
     ]
    }
   ],
   "source": [
    "# Main \n",
    "pcap_path = os.path.join(PCAP_DIR, 'master.cap')\n",
    "# feature_extractor(pcap_path)\n",
    "wifi_extract_packet_features(create_master=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini       104280\n",
      "Router     103593\n",
      "Dropcam     64568\n",
      "Kasa        23753\n",
      "Netcam3      4867\n",
      "Netcam1      4446\n",
      "Netcam2      4407\n",
      "Switch2      3046\n",
      "Switch1      2668\n",
      "Switch3      2634\n",
      "Insight      2556\n",
      "Switch4      2206\n",
      "Lifx2         627\n",
      "TpPlug        587\n",
      "Lifx1         540\n",
      "TpBulb        202\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = make_dataframe()\n",
    "\n",
    "# Limit to two device types\n",
    "# df = df[(df[\"DeviceType\"]!=\"bulb\") & (df[\"DeviceType\"]!=\"router\")]\n",
    "\n",
    "# Take out packets from router\n",
    "df = df[df[\"DeviceType\"]!=\"router\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs all\n",
      "Device Type: camera\n",
      "Random Forest Score: 0.2422596754057428 Time:  0.523423194885\n",
      "KNN Score: 0.2833645443196005 Time:  96.3279111385\n",
      "LDA Score: 0.16086142322097377 Time:  0.143582105637\n",
      "Total time (classifiers): 96.9950249195\n",
      "\n",
      "Device Type: bulb\n",
      "Random Forest Score: 0.9948813982521848 Time:  0.538688182831\n",
      "KNN Score: 0.9814294631710362 Time:  96.1647100449\n",
      "LDA Score: 1.0 Time:  0.13214802742\n",
      "Total time (classifiers): 96.8356180191\n",
      "\n",
      "Device Type: plug\n",
      "Random Forest Score: 0.9485018726591761 Time:  0.669028997421\n",
      "KNN Score: 0.26523096129837703 Time:  96.5410609245\n",
      "LDA Score: 0.8838639200998751 Time:  0.131011009216\n",
      "Total time (classifiers): 97.3411831856\n",
      "\n",
      "Total time (one vs all_classify): 291.240507126\n",
      "\n",
      "One vs one\n",
      "Device Pair: ('camera', 'bulb')\n",
      "Random Forest Score: 0.748452832769173 Time:  0.431248188019\n",
      "KNN Score: 0.9996580845898725 Time:  9.26896500587\n",
      "LDA Score: 1.0 Time:  0.0487349033356\n",
      "Total time (classifiers): 9.74901199341\n",
      "\n",
      "Device Pair: ('camera', 'plug')\n",
      "Random Forest Score: 0.7731830770700029 Time:  0.511701107025\n",
      "KNN Score: 0.1357718142170439 Time:  98.0016429424\n",
      "LDA Score: 0.8816413586731608 Time:  0.13197684288\n",
      "Total time (classifiers): 98.6454029083\n",
      "\n",
      "Device Pair: ('bulb', 'plug')\n",
      "Random Forest Score: 0.8283625730994152 Time:  0.379930019379\n",
      "KNN Score: 0.8269005847953217 Time:  29.9492669106\n",
      "LDA Score: 1.0 Time:  0.148400068283\n",
      "Total time (classifiers): 30.4776940346\n",
      "\n",
      "Total time (one vs one_classify): 139.112354994\n",
      "\n",
      "Total time (one vs one & one vs all classification): 430.362438917\n"
     ]
    }
   ],
   "source": [
    "# Run One vs All  and One vs One classification strategies\n",
    "features_list = [\n",
    "        # Packet info\n",
    "        \"PacketLength\", \"Duration\", \n",
    "        \n",
    "        # Vendor \n",
    "         \"Belkin\", \"Dropcam\", \"Lifi\", \"Netgear\", \"Tp-link\",\n",
    "    \n",
    "        # 802.11 Data subtype\n",
    "        \"Data\", \"QoS_Data\", \"QoS_Null\",\n",
    "\n",
    "        # Associated Packets\n",
    "        \"Assoc_Packets\"]\n",
    "\n",
    "y_list = [\"camera\", \"bulb\", \"plug\"]\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "print \"One vs all\"\n",
    "one_vs_all_classify(df, features_list, y_list)\n",
    "\n",
    "print \"One vs one\"\n",
    "one_vs_one_classify(df, features_list, y_list)\n",
    "\n",
    "print \"Total time (one vs one & one vs all classification):\", time.time() - time_start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
