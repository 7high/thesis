{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, datetime, getopt, glob, logging, os, sys, time\n",
    "import helpers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyshark\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "ROUTER = '78:d2:94:4d:ab:3e'\n",
    "WIFI_DEVICES = ['ec:1a:59:e4:fd:41', 'ec:1a:59:e4:fa:09',\n",
    "                'ec:1a:59:e5:02:0d', '14:91:82:24:dd:35',\n",
    "                '60:38:e0:ee:7c:e5', '14:91:82:cd:df:3d',\n",
    "                'b4:75:0e:0d:94:65', 'b4:75:0e:0d:33:d5',\n",
    "                '94:10:3e:2b:7a:55', '30:8c:fb:3a:1a:ad',\n",
    "                'd0:73:d5:26:b8:4c', 'd0:73:d5:26:c9:27',\n",
    "                'ac:84:c6:97:7c:cc', 'b0:4e:26:c5:2a:41',\n",
    "                '70:4f:57:f9:e1:b8', ROUTER]\n",
    "\n",
    "DEVICE_TYPE = {'ec:1a:59:e4:fd:41' : 'camera',\n",
    "               'ec:1a:59:e4:fa:09' : 'camera',\n",
    "               'ec:1a:59:e5:02:0d' : 'camera',\n",
    "               '14:91:82:24:dd:35' : 'plug',\n",
    "               '60:38:e0:ee:7c:e5' : 'plug',\n",
    "               '14:91:82:cd:df:3d' : 'plug',\n",
    "               'b4:75:0e:0d:94:65' : 'plug',\n",
    "               'b4:75:0e:0d:33:d5' : 'plug',\n",
    "               '94:10:3e:2b:7a:55' : 'plug',\n",
    "               '30:8c:fb:3a:1a:ad' : 'camera',\n",
    "               'd0:73:d5:26:b8:4c' : 'bulb', \n",
    "               'd0:73:d5:26:c9:27' : 'bulb',\n",
    "               'ac:84:c6:97:7c:cc' : 'camera', \n",
    "               'b0:4e:26:c5:2a:41' : 'bulb',\n",
    "               '70:4f:57:f9:e1:b8' : 'plug',\n",
    "                ROUTER : 'router'}\n",
    "\n",
    "DEVICE_NAME = {'ec:1a:59:e4:fd:41' : 'Netcam1', \n",
    "               'ec:1a:59:e4:fa:09' : 'Netcam2',\n",
    "               'ec:1a:59:e5:02:0d' : 'Netcam3',\n",
    "               '14:91:82:24:dd:35' : 'Insight',\n",
    "               '60:38:e0:ee:7c:e5' : 'Mini',\n",
    "               '14:91:82:cd:df:3d' : 'Switch1',\n",
    "               'b4:75:0e:0d:94:65' : 'Switch2',\n",
    "               'b4:75:0e:0d:33:d5' : 'Switch3',\n",
    "               '94:10:3e:2b:7a:55' : 'Switch4',\n",
    "               '30:8c:fb:3a:1a:ad' : 'Dropcam',\n",
    "               'd0:73:d5:26:b8:4c' : 'Lifx1', \n",
    "               'd0:73:d5:26:c9:27' : 'Lifx2',\n",
    "               'ac:84:c6:97:7c:cc' : 'Kasa', \n",
    "               'b0:4e:26:c5:2a:41' : 'TpBulb',\n",
    "               '70:4f:57:f9:e1:b8' : 'TpPlug',\n",
    "                ROUTER : 'Router'}\n",
    "\n",
    "TRAINING_TEST = {'ec:1a:59:e4:fd:41' : 'train', \n",
    "                 'ec:1a:59:e4:fa:09' : 'train',\n",
    "                 'ec:1a:59:e5:02:0d' : 'test',\n",
    "                 '14:91:82:24:dd:35' : 'train',\n",
    "                 '60:38:e0:ee:7c:e5' : 'train',\n",
    "                 '14:91:82:cd:df:3d' : 'train',\n",
    "                 'b4:75:0e:0d:94:65' : 'train',\n",
    "                 'b4:75:0e:0d:33:d5' : 'train',\n",
    "                 '94:10:3e:2b:7a:55' : 'test',\n",
    "                 '30:8c:fb:3a:1a:ad' : 'train',\n",
    "                 'd0:73:d5:26:b8:4c' : 'train', \n",
    "                 'd0:73:d5:26:c9:27' : 'test',\n",
    "                 'ac:84:c6:97:7c:cc' : 'test', \n",
    "                 'b0:4e:26:c5:2a:41' : 'train',\n",
    "                 '70:4f:57:f9:e1:b8' : 'test',\n",
    "}\n",
    "\n",
    "FEATURES = [\"Time\", \"PacketLength\", \"Duration\", \"SourceAddr\", \"DestAddr\", \"SubtypeNum\"]\n",
    "SRC_DIR = './Source/'\n",
    "DST_DIR = './Destination/'\n",
    "PCAP_DIR = '/root/Documents/Thesis/PCAPS'\n",
    "TIMING_PKT_NUMBER = 25000\n",
    "DATA_FRAME_TYPE = '2'\n",
    "\n",
    "path_name = os.getcwd()\n",
    "DATE = path_name[path_name.rindex('/')+1:]\n",
    "PROC_TIME = \"wifi_processing_time_\" + DATE + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_packet(pkt, tgt_files_by_src, tgt_files_by_dst):\n",
    "    \"\"\"\n",
    "    Parses a given packet and extracts the following features:\n",
    "        - destination MAC address\n",
    "        - source MAC address\n",
    "        - time of transmission\n",
    "        - packet length\n",
    "        \n",
    "    The features of the packet are written out to a csv row, which is\n",
    "    in turn written out to a csv file in the given dictionaries.\n",
    "    \n",
    "    This code is heavily based on code written by Capt Steven Beyer.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pkt: (Pyshark packet object) the packet from which features will be extracted\n",
    "    tgt_files_by_src: (dictionary) a dictionary of open csv files.\n",
    "        The keys are device source addresses, and the values are the open csv files.\n",
    "    tgt_files_by_dst: (dictionary) a dictionary of open csv files.\n",
    "        The keys are device destination addresses, and the values are the open csv files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pkt_dst = pkt.wlan.da\n",
    "        pkt_src = pkt.wlan.sa\n",
    "        \n",
    "#         if (pkt_src in WIFI_DEVICES) and (pkt_dst in WIFI_DEVICES):\n",
    "        if (pkt_src in WIFI_DEVICES):\n",
    "            # Extract features\n",
    "            pkt_time = pkt.frame_info.time_epoch\n",
    "            pkt_len = pkt.length\n",
    "            pkt_duration = pkt.wlan.duration\n",
    "            pkt_subtype_num = pkt.wlan.fc_type_subtype\n",
    "            \n",
    "            # Output matches FEATURES\n",
    "            output = [pkt_time, pkt_len, pkt_duration, pkt_src, pkt_dst, pkt_subtype_num]\n",
    "            \n",
    "            csv.writer(tgt_files_by_src[pkt_src]).writerow(output)\n",
    "#             csv.writer(tgt_files_by_dst[pkt_dst]).writerow(output)\n",
    "            \n",
    "    \n",
    "    except AttributeError:\n",
    "        print \"ignored: \", pkt.number            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mac_vendors():\n",
    "    \"\"\"\n",
    "    Uses the macvendors.co API to lookup the vendors of Wi-Fi devices.\n",
    "    Requires internet access.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    device_vendors (dict): keys(str) = WIFI_DEVICES MAC addresses, values(str) = vendor names\n",
    "    \"\"\"\n",
    "    import json, requests\n",
    "\n",
    "    # Get JSON response from API\n",
    "    vendors_json = []\n",
    "    for addr in WIFI_DEVICES:\n",
    "        response = requests.get('http://macvendors.co/api/' + addr).text\n",
    "        vendors_json.append(response)\n",
    "\n",
    "    # Extracting company from API response\n",
    "    vendors = []\n",
    "    for vendor_json in vendors_json:\n",
    "        response = json.loads(vendor_json)\n",
    "        company = str(response['result']['company']).split(' ',1)[0].capitalize()\n",
    "        vendors.append(company)\n",
    "\n",
    "    # Put device MAC addresses and vendors into dictionary\n",
    "    device_vendors = dict(zip(WIFI_DEVICES, vendors))\n",
    "    \n",
    "    return device_vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(filename = os.path.join(PCAP_DIR, 'master.cap'), create_master=True):\n",
    "    \"\"\"\n",
    "    Unit that extracts wanted features out of packets in a packet capture file.\n",
    "    The feature_extractor focuses on features derived from packet information. \n",
    "    Secondary features will be processed by the make_dataframe function.\n",
    "    Produces two csv files for each device in WIFI_DEVICES (see Global Variables).\n",
    "    One file is for all packets where the device is the source; the other is where the device is the destination.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: (string) the absolute path of the packet capture file\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    Source directory: (filesystem) creates a directory containing csv files for each device \n",
    "        where it is the source of the packet\n",
    "    Destination directory: (filesystem) creates a directory containing csv files for each device \n",
    "        where it is the destination of the packet\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    none\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare writers\n",
    "    pt_file = open(PROC_TIME, 'w')\n",
    "    csv.writer(pt_file).writerow([\"Unit\", \"Total Packets Processed\", \"Total Process Time\", \"Average Process Time\"])\n",
    "    pt_file.close()\n",
    "\n",
    "    # Initialize counters\n",
    "    pkt_count = 0\n",
    "    total_time_processing = 0\n",
    "    total_time_start = time.time()\n",
    "\n",
    "    # Initialize dicts for each device\n",
    "    tgt_files_by_src = {}\n",
    "    tgt_files_by_dst = {}\n",
    "    \n",
    "    # Combine all pcaps in directory in one master pcap\n",
    "    if (create_master):\n",
    "        try:\n",
    "            ret = os.system('mergecap /root/Documents/Thesis/PCAPS/wifi* -w /root/Documents/Thesis/PCAPS/master.cap')\n",
    "            if ret != 0:\n",
    "                raise OSError\n",
    "        except OSError:\n",
    "            print 'Could not make master capture file'\n",
    "\n",
    "    # Initialize capture file \n",
    "    cap = pyshark.FileCapture(filename, only_summaries=False)\n",
    "\n",
    "    # Get time of first packet\n",
    "    prev_pkt_time = cap[0].frame_info.time_epoch\n",
    "\n",
    "    # Initialize output folders\n",
    "    helpers.init_dirs()\n",
    "    \n",
    "    # Open output files for each Wi-Fi device\n",
    "    for device in WIFI_DEVICES:\n",
    "        tgt_files_by_src[device] = open(SRC_DIR + device.replace(':', '.') + \".csv\", 'a')\n",
    "        tgt_files_by_dst[device] = open(DST_DIR + device.replace(':', '.') + \".csv\", 'a')\n",
    "\n",
    "        \n",
    "        # Initialize with column headers\n",
    "        csv.writer(tgt_files_by_src[device]).writerow(FEATURES)\n",
    "        csv.writer(tgt_files_by_dst[device]).writerow(FEATURES)\n",
    "    \n",
    "    # Go through each packet in capture, and store pertinent packets to csv files\n",
    "    for pkt in cap:\n",
    "        pkt_count += 1\n",
    "\n",
    "        time_start = time.time()\n",
    "        if pkt.wlan.fc_type == DATA_FRAME_TYPE:\n",
    "            parse_packet(pkt, tgt_files_by_src, tgt_files_by_dst)\n",
    "            total_time_processing += time.time() - time_start\n",
    "\n",
    "    total_time = time.time() - total_time_start\n",
    "    \n",
    "    # Close files\n",
    "    for open_file in tgt_files_by_src.values():\n",
    "        open_file.close()\n",
    "\n",
    "    for open_file in tgt_files_by_dst.values():\n",
    "        open_file.close()\n",
    "        \n",
    "    # Rename files to device names for readability\n",
    "    helpers.rename_csv_files(DEVICE_NAME)\n",
    "        \n",
    "    # Calculate time variables\n",
    "    final_time = time.time()\n",
    "    normalized_total_time = (TIMING_PKT_NUMBER * total_time) / pkt_count\n",
    "    normalized_processing_time = (TIMING_PKT_NUMBER * total_time_processing) / pkt_count\n",
    "\n",
    "    # Print time variables\n",
    "    print \"Total number of packets processed: \", pkt_count\n",
    "    print \"Total data processing time: \", total_time\n",
    "    print \"Normalized total processing time per 25k packets: \", normalized_total_time\n",
    "    print \"Total capture file processing time: \", total_time_processing\n",
    "    print \"Normalized capture file processing time: \", normalized_processing_time\n",
    "\n",
    "    # Print out time metrics to csv\n",
    "    pt_file = open(PROC_TIME, 'a')\n",
    "    csv.writer(pt_file).writerow([\"Packet capture iteration\", pkt_count, total_time_processing, normalized_processing_time])\n",
    "    csv.writer(pt_file).writerow([\"Component start and finish time\", total_time_start, final_time, final_time-total_time_start])\n",
    "    pt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_dataframe(path='/root/Documents/Thesis/Code/Source'):\n",
    "    \"\"\"\n",
    "    Unit that takes all the csv files produced by the feature_extractor unit and puts them into a pandas dataframe.\n",
    "    Returns a clean dataframe with all good data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: (filesystem) the absolute path of the folder containing the csv files\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    none\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe: (pandas dataframe) a useful data structure for machine learning\n",
    "    counts: (pandas series) packet counts for each device \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    DATA_PKT_SUBTYPES = {32 : 'Data',\n",
    "                         40 : 'QoS_Data',\n",
    "                         44 : 'QoS_Null'}\n",
    "    \n",
    "    # Search the path for csv files\n",
    "#     path='/root/Documents/Thesis/Code/Source'\n",
    "    all_csvs = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "    # Collect all csvs in one dataframe\n",
    "    df_from_each_file = (pd.read_csv(f) for f in all_csvs)\n",
    "    df = pd.concat(df_from_each_file, ignore_index=True, sort=False)\n",
    "\n",
    "    # Add device type, device ID of each packet\n",
    "    df[\"DeviceType\"] = df[\"SourceAddr\"].map(DEVICE_TYPE)\n",
    "    df[\"Name\"] = df[\"SourceAddr\"].map(DEVICE_NAME)\n",
    "    \n",
    "    # Add whether device is a training or test device\n",
    "    df[\"Set\"] = df[\"SourceAddr\"].map(TRAINING_TEST)\n",
    "    \n",
    "    # Add MAC vendors as one-hot encoding\n",
    "    df[\"Vendor\"] = df[\"SourceAddr\"].map(get_mac_vendors())\n",
    "    vendor_series = pd.get_dummies(df[\"Vendor\"])\n",
    "    df = pd.concat([df, vendor_series], axis=1)\n",
    "\n",
    "    # One-hot encode packet subtype\n",
    "    df[\"Subtype\"] = df[\"SubtypeNum\"].map(DATA_PKT_SUBTYPES)\n",
    "    subtype_series = pd.get_dummies(df[\"Subtype\"])\n",
    "    df = pd.concat([df, subtype_series], axis=1)\n",
    "    \n",
    "    # Set addresses as categorical data\n",
    "    \n",
    "    \n",
    "    # Count packets for each device\n",
    "    device_counts = df[\"Name\"].value_counts()\n",
    "    print device_counts\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    randomforest = RandomForestClassifier(random_state=0, n_jobs=2)\n",
    "    rf_model = randomforest.fit(X_train, y_train)\n",
    "\n",
    "    preds = rf_model.predict(X_test)\n",
    "    score = rf_model.score(X_test, y_test)\n",
    "    \n",
    "    time_elapsed = time.time() - time_start\n",
    "    return score, time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbors_classifier(X_train, y_train, X_test, y_test):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=5, n_jobs=2)\n",
    "    knn_model = knn.fit(X_train, y_train)\n",
    "    \n",
    "    preds = knn_model.predict(X_test)\n",
    "    score = knn_model.score(X_test, y_test)\n",
    "    \n",
    "    time_elapsed = time.time() - time_start\n",
    "    return score, time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_classifier(X_train, y_train, X_test, y_test):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda_model = lda.fit(X_train, y_train)\n",
    "    \n",
    "    preds = lda_model.predict(X_test)\n",
    "    score = lda_model.score(X_test, y_test)\n",
    "    \n",
    "    time_elapsed = time.time() - time_start\n",
    "    return score, time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old ./Source deleted\n",
      "Old ./Destination deleted\n",
      "Total number of packets processed:  1011608\n",
      "Total data processing time:  1125.12533116\n",
      "Normalized total processing time per 25k packets:  27.8053685608\n",
      "Total capture file processing time:  96.6678524017\n",
      "Normalized capture file processing time:  2.38896520198\n"
     ]
    }
   ],
   "source": [
    "# Main \n",
    "pcap_path = os.path.join(PCAP_DIR, 'master.cap')\n",
    "# feature_extractor(pcap_path)\n",
    "feature_extractor(create_master=False)\n",
    "# df = make_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm just testing some code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini       67881\n",
      "Router     65187\n",
      "Dropcam    42359\n",
      "Kasa       15465\n",
      "Netcam3     3596\n",
      "Netcam2     2946\n",
      "Netcam1     2912\n",
      "Switch2     2111\n",
      "Switch1     1763\n",
      "Insight     1701\n",
      "Switch3     1677\n",
      "Switch4     1432\n",
      "TpPlug       419\n",
      "Lifx2        203\n",
      "Lifx1        164\n",
      "TpBulb        19\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = make_dataframe()\n",
    "\n",
    "# Limit to two device types\n",
    "# df = df[(df[\"DeviceType\"]!=\"bulb\") & (df[\"DeviceType\"]!=\"router\")]\n",
    "\n",
    "# Take out packets from router\n",
    "df = df[df[\"DeviceType\"]!=\"router\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123533, 10) (21115, 10) (123533,) (21115,)\n",
      "plug      75133\n",
      "camera    48217\n",
      "bulb        183\n",
      "Name: DeviceType, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Divide into training and test sets\n",
    "\n",
    "\"\"\"\n",
    "# Use StratifiedShuffleSplit to create train and test sets\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "X = df[[\n",
    "        # Packet info\n",
    "        \"PacketLength\", \"Duration\", \n",
    "        \n",
    "        # Vendor \n",
    "        \"Belkin\", \"Dropcam\", \"Lifi\", \"Netgear\", \"Tp-link\",\n",
    "    \n",
    "        # 802.11 Data subtype\n",
    "        \"Data\", \"QoS_Data\", \"QoS_Null\"]]\n",
    "y = df[\"DeviceType\"]\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\"\"\"\n",
    "\n",
    "# Divide df by train and test devices\n",
    "df_test = df[df[\"Set\"]==\"test\"]\n",
    "df_train = df[df[\"Set\"]==\"train\"]\n",
    "X_train = df_train[[\n",
    "        # Packet info\n",
    "        \"PacketLength\", \"Duration\", \n",
    "        \n",
    "        # Vendor \n",
    "        \"Belkin\", \"Dropcam\", \"Lifi\", \"Netgear\", \"Tp-link\",\n",
    "    \n",
    "        # 802.11 Data subtype\n",
    "        \"Data\", \"QoS_Data\", \"QoS_Null\"]]\n",
    "\n",
    "y_train = df_train[\"DeviceType\"]\n",
    "\n",
    "X_test = df_test[[\n",
    "        # Packet info\n",
    "        \"PacketLength\", \"Duration\", \n",
    "        \n",
    "        # Vendor \n",
    "        \"Belkin\", \"Dropcam\", \"Lifi\", \"Netgear\", \"Tp-link\",\n",
    "    \n",
    "        # 802.11 Data subtype\n",
    "        \"Data\", \"QoS_Data\", \"QoS_Null\"]]\n",
    "\n",
    "y_test = df_test[\"DeviceType\"]\n",
    "\n",
    "\n",
    "\n",
    "# print X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "# print y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score: 0.1396163864551267 Time:  0.545241117477\n",
      "KNN Score: 0.6162443760359934 Time:  40.8953938484\n",
      "LDA Score: 0.8699976320151551 Time:  0.307951927185\n"
     ]
    }
   ],
   "source": [
    "# Run classifiers\n",
    "rf_clf = random_forest_classifier(X_train, y_train, X_test, y_test)\n",
    "knn_clf = k_neighbors_classifier(X_train, y_train, X_test, y_test)\n",
    "lda_clf = lda_classifier(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print \"Random Forest Score:\", rf_clf[0], \"Time: \", rf_clf[1]\n",
    "print \"KNN Score:\", knn_clf[0], \"Time: \", knn_clf[1]\n",
    "print \"LDA Score:\", lda_clf[0], \"Time: \", lda_clf[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
