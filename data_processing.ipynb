{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, datetime, getopt, glob, itertools, logging, os, sys, time\n",
    "import helpers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyshark\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "ROUTER = '78:d2:94:4d:ab:3e'\n",
    "WIFI_DEVICES = ['ec:1a:59:e4:fd:41', 'ec:1a:59:e4:fa:09',\n",
    "                'ec:1a:59:e5:02:0d', '14:91:82:24:dd:35',\n",
    "                '60:38:e0:ee:7c:e5', '14:91:82:cd:df:3d',\n",
    "                'b4:75:0e:0d:94:65', 'b4:75:0e:0d:33:d5',\n",
    "                '94:10:3e:2b:7a:55', '30:8c:fb:3a:1a:ad',\n",
    "                'd0:73:d5:26:b8:4c', 'd0:73:d5:26:c9:27',\n",
    "                'ac:84:c6:97:7c:cc', 'b0:4e:26:c5:2a:41',\n",
    "                '70:4f:57:f9:e1:b8', ROUTER]\n",
    "\n",
    "DEVICE_NAME = {'ec:1a:59:e4:fd:41' : 'Netcam1', \n",
    "               'ec:1a:59:e4:fa:09' : 'Netcam2',\n",
    "               'ec:1a:59:e5:02:0d' : 'Netcam3',\n",
    "               '14:91:82:24:dd:35' : 'Insight',\n",
    "               '60:38:e0:ee:7c:e5' : 'Mini',\n",
    "               '14:91:82:cd:df:3d' : 'Switch1',\n",
    "               'b4:75:0e:0d:94:65' : 'Switch2',\n",
    "               'b4:75:0e:0d:33:d5' : 'Switch3',\n",
    "               '94:10:3e:2b:7a:55' : 'Switch4',\n",
    "               '30:8c:fb:3a:1a:ad' : 'Dropcam',\n",
    "               'd0:73:d5:26:b8:4c' : 'Lifx1', \n",
    "               'd0:73:d5:26:c9:27' : 'Lifx2',\n",
    "               'ac:84:c6:97:7c:cc' : 'Kasa', \n",
    "               'b0:4e:26:c5:2a:41' : 'TpBulb',\n",
    "               '70:4f:57:f9:e1:b8' : 'TpPlug',\n",
    "                ROUTER : 'Router'}\n",
    "\n",
    "DEVICE_TYPE = {'ec:1a:59:e4:fd:41' : 'camera',\n",
    "               'ec:1a:59:e4:fa:09' : 'camera',\n",
    "               'ec:1a:59:e5:02:0d' : 'camera',\n",
    "               '14:91:82:24:dd:35' : 'plug',\n",
    "               '60:38:e0:ee:7c:e5' : 'plug',\n",
    "               '14:91:82:cd:df:3d' : 'plug',\n",
    "               'b4:75:0e:0d:94:65' : 'plug',\n",
    "               'b4:75:0e:0d:33:d5' : 'plug',\n",
    "               '94:10:3e:2b:7a:55' : 'plug',\n",
    "               '30:8c:fb:3a:1a:ad' : 'camera',\n",
    "               'd0:73:d5:26:b8:4c' : 'bulb', \n",
    "               'd0:73:d5:26:c9:27' : 'bulb',\n",
    "               'ac:84:c6:97:7c:cc' : 'camera', \n",
    "               'b0:4e:26:c5:2a:41' : 'bulb',\n",
    "               '70:4f:57:f9:e1:b8' : 'plug',\n",
    "                ROUTER : 'router'}\n",
    "\n",
    "TRAINING_TEST = {'ec:1a:59:e4:fd:41' : 'train', \n",
    "                 'ec:1a:59:e4:fa:09' : 'train',\n",
    "                 'ec:1a:59:e5:02:0d' : 'test',\n",
    "                 '14:91:82:24:dd:35' : 'train',\n",
    "                 '60:38:e0:ee:7c:e5' : 'train',\n",
    "                 '14:91:82:cd:df:3d' : 'train',\n",
    "                 'b4:75:0e:0d:94:65' : 'train',\n",
    "                 'b4:75:0e:0d:33:d5' : 'train',\n",
    "                 '94:10:3e:2b:7a:55' : 'test',\n",
    "                 '30:8c:fb:3a:1a:ad' : 'train',\n",
    "                 'd0:73:d5:26:b8:4c' : 'train', \n",
    "                 'd0:73:d5:26:c9:27' : 'test',\n",
    "                 'ac:84:c6:97:7c:cc' : 'test', \n",
    "                 'b0:4e:26:c5:2a:41' : 'train',\n",
    "                 '70:4f:57:f9:e1:b8' : 'test'}\n",
    "\n",
    "DATA_PKT_SUBTYPES = {32 : 'Data',\n",
    "                     40 : 'QoS_Data',\n",
    "                     44 : 'QoS_Null'}\n",
    "\n",
    "FEATURES = [\"Time\", \"PacketLength\", \"Duration\", \"SourceAddr\", \"DestAddr\", \"SubtypeNum\"]\n",
    "SRC_DIR = './Source/'\n",
    "DST_DIR = './Destination/'\n",
    "PCAP_DIR = '/root/Documents/Thesis/PCAPS'\n",
    "TIMING_PKT_NUMBER = 25000\n",
    "DATA_FRAME_TYPE = '2'\n",
    "\n",
    "path_name = os.getcwd()\n",
    "DATE = path_name[path_name.rindex('/')+1:]\n",
    "PROC_TIME = \"wifi_processing_time_\" + DATE + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_packet(pkt, tgt_files_by_src, tgt_files_by_dst):\n",
    "    \"\"\"\n",
    "    Parses a given packet and extracts the following features:\n",
    "        - destination MAC address\n",
    "        - source MAC address\n",
    "        - time of transmission\n",
    "        - packet length\n",
    "        \n",
    "    The features of the packet are written out to a csv row, which is\n",
    "    in turn written out to a csv file in the given dictionaries.\n",
    "    \n",
    "    This code is heavily based on code written by Capt Steven Beyer.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pkt: (Pyshark packet object) the packet from which features will be extracted\n",
    "    tgt_files_by_src: (dictionary) a dictionary of open csv files.\n",
    "        The keys are device source addresses, and the values are the open csv files.\n",
    "    tgt_files_by_dst: (dictionary) a dictionary of open csv files.\n",
    "        The keys are device destination addresses, and the values are the open csv files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pkt_dst = pkt.wlan.da\n",
    "        pkt_src = pkt.wlan.sa\n",
    "        \n",
    "#         if (pkt_src in WIFI_DEVICES) and (pkt_dst in WIFI_DEVICES):\n",
    "        if (pkt_src in WIFI_DEVICES):\n",
    "            # Extract features\n",
    "            pkt_time = pkt.frame_info.time_epoch\n",
    "            pkt_len = pkt.length\n",
    "            pkt_duration = pkt.wlan.duration\n",
    "            pkt_subtype_num = pkt.wlan.fc_type_subtype\n",
    "            \n",
    "            # Output matches FEATURES\n",
    "            output = [pkt_time, pkt_len, pkt_duration, pkt_src, pkt_dst, pkt_subtype_num]\n",
    "            \n",
    "            csv.writer(tgt_files_by_src[pkt_src]).writerow(output)\n",
    "#             csv.writer(tgt_files_by_dst[pkt_dst]).writerow(output)\n",
    "            \n",
    "    \n",
    "    except AttributeError:\n",
    "        print \"ignored: \", pkt.number            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mac_vendors():\n",
    "    \"\"\"\n",
    "    Uses the macvendors.co API to lookup the vendors of Wi-Fi devices.\n",
    "    Requires internet access.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    device_vendors (dict): keys(str) = WIFI_DEVICES MAC addresses, values(str) = vendor names\n",
    "    \"\"\"\n",
    "    import json, requests\n",
    "\n",
    "    # Get JSON response from API\n",
    "    vendors_json = []\n",
    "    for addr in WIFI_DEVICES:\n",
    "        response = requests.get('http://macvendors.co/api/' + addr).text\n",
    "        vendors_json.append(response)\n",
    "\n",
    "    # Extracting company from API response\n",
    "    vendors = []\n",
    "    for vendor_json in vendors_json:\n",
    "        response = json.loads(vendor_json)\n",
    "        company = str(response['result']['company']).split(' ',1)[0].capitalize()\n",
    "        vendors.append(company)\n",
    "\n",
    "    # Put device MAC addresses and vendors into dictionary\n",
    "    device_vendors = dict(zip(WIFI_DEVICES, vendors))\n",
    "    \n",
    "    return device_vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_packet_features(filename = os.path.join(PCAP_DIR, 'master.cap'), create_master=True):\n",
    "    \"\"\"\n",
    "    Unit that extracts wanted features out of packets in a packet capture file.\n",
    "    The feature_extractor focuses on features derived from packet information. \n",
    "    Secondary features are processed by the make_dataframe function.\n",
    "    Produces two csv files for each device in WIFI_DEVICES (see Global Variables).\n",
    "    One file is for all packets where the device is the source; the other is where the device is the destination.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: (string) the absolute path of the packet capture file\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    Source directory: (filesystem) creates a directory containing csv files for each device \n",
    "        where it is the source of the packet\n",
    "    Destination directory: (filesystem) creates a directory containing csv files for each device \n",
    "        where it is the destination of the packet\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    none\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare writers\n",
    "    pt_file = open(PROC_TIME, 'w')\n",
    "    csv.writer(pt_file).writerow([\"Unit\", \"Total Packets Processed\", \"Total Process Time\", \"Average Process Time\"])\n",
    "    pt_file.close()\n",
    "\n",
    "    # Initialize counters\n",
    "    pkt_count = 0\n",
    "    total_time_processing = 0\n",
    "    total_time_start = time.time()\n",
    "\n",
    "    # Initialize dicts for each device\n",
    "    tgt_files_by_src = {}\n",
    "    tgt_files_by_dst = {}\n",
    "    \n",
    "    # Combine all pcaps in directory in one master pcap\n",
    "    if (create_master):\n",
    "        try:\n",
    "            ret = os.system('mergecap /root/Documents/Thesis/PCAPS/wifi* -w /root/Documents/Thesis/PCAPS/master.cap')\n",
    "            if ret != 0:\n",
    "                raise OSError\n",
    "        except OSError:\n",
    "            print 'Could not make master capture file'\n",
    "\n",
    "    # Initialize capture file \n",
    "    cap = pyshark.FileCapture(filename, only_summaries=False)\n",
    "\n",
    "    # Get time of first packet\n",
    "    prev_pkt_time = cap[0].frame_info.time_epoch\n",
    "\n",
    "    # Initialize output folders\n",
    "    helpers.init_dirs()\n",
    "    \n",
    "    # Open output files for each Wi-Fi device\n",
    "    for device in WIFI_DEVICES:\n",
    "        tgt_files_by_src[device] = open(SRC_DIR + device.replace(':', '.') + \".csv\", 'a')\n",
    "        tgt_files_by_dst[device] = open(DST_DIR + device.replace(':', '.') + \".csv\", 'a')\n",
    "\n",
    "        \n",
    "        # Initialize with column headers\n",
    "        csv.writer(tgt_files_by_src[device]).writerow(FEATURES)\n",
    "        csv.writer(tgt_files_by_dst[device]).writerow(FEATURES)\n",
    "    \n",
    "    # Go through each packet in capture, and store pertinent packets to csv files\n",
    "    for pkt in cap:\n",
    "        pkt_count += 1\n",
    "\n",
    "        time_start_singlepacket = time.time()\n",
    "        if pkt.wlan.fc_type == DATA_FRAME_TYPE:\n",
    "            parse_packet(pkt, tgt_files_by_src, tgt_files_by_dst)\n",
    "            total_time_processing += time.time() - time_start_singlepacket\n",
    "\n",
    "    total_time_elapsed = time.time() - total_time_start\n",
    "    \n",
    "    # Close files\n",
    "    for open_file in tgt_files_by_src.values():\n",
    "        open_file.close()\n",
    "\n",
    "    for open_file in tgt_files_by_dst.values():\n",
    "        open_file.close()\n",
    "        \n",
    "    # Rename files to device names for readability\n",
    "    helpers.rename_csv_files(DEVICE_NAME)\n",
    "        \n",
    "    # Calculate time variables\n",
    "    final_time = time.time()\n",
    "    normalized_total_time = (TIMING_PKT_NUMBER * total_time_elapsed) / pkt_count\n",
    "    normalized_processing_time = (TIMING_PKT_NUMBER * total_time_processing) / pkt_count\n",
    "\n",
    "    # Print time variables\n",
    "    print \"Total number of packets processed: \", pkt_count\n",
    "    print \"Total data processing time: \", total_time_elapsed\n",
    "    print \"Normalized total processing time per 25k packets: \", normalized_total_time\n",
    "    print \"Total capture file processing time: \", total_time_processing\n",
    "    print \"Normalized capture file processing time: \", normalized_processing_time\n",
    "\n",
    "    # Print out time metrics to csv\n",
    "    pt_file = open(PROC_TIME, 'a')\n",
    "    csv.writer(pt_file).writerow([\"Packet capture iteration\", pkt_count, total_time_processing, normalized_processing_time])\n",
    "    csv.writer(pt_file).writerow([\"Component start and finish time\", total_time_start, final_time, final_time-total_time_start])\n",
    "    pt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_dataframe(path='/root/Documents/Thesis/Code/Source'):\n",
    "    \"\"\"\n",
    "    Unit that takes all the csv files produced by the feature_extractor unit and puts them into a pandas dataframe.\n",
    "    Returns a clean dataframe with all good data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: (filesystem) the absolute path of the folder containing the csv files\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    none\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe: (pandas dataframe) a useful data structure for machine learning\n",
    "    counts: (pandas series) packet counts for each device \n",
    "    \"\"\"\n",
    "    \n",
    "    # Search the path for csv files\n",
    "#     path='/root/Documents/Thesis/Code/Source'\n",
    "    all_csvs = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "    # Collect all csvs in one dataframe\n",
    "    df_from_each_file = (pd.read_csv(f) for f in all_csvs)\n",
    "    df = pd.concat(df_from_each_file, ignore_index=True, sort=False)\n",
    "\n",
    "    # Add device type, device ID of each packet\n",
    "    df[\"DeviceType\"] = df[\"SourceAddr\"].map(DEVICE_TYPE)\n",
    "    df[\"Name\"] = df[\"SourceAddr\"].map(DEVICE_NAME)\n",
    "    \n",
    "    # Add whether device is a training or test device\n",
    "    df[\"Set\"] = df[\"SourceAddr\"].map(TRAINING_TEST)\n",
    "    \n",
    "    # One-hot encode device type (response variable)\n",
    "    deviceType_series = pd.get_dummies(df[\"DeviceType\"])\n",
    "    df = pd.concat([df, deviceType_series], axis=1)\n",
    "    \n",
    "    # One-hot encode MAC vendors\n",
    "    df[\"Vendor\"] = df[\"SourceAddr\"].map(get_mac_vendors())\n",
    "    vendor_series = pd.get_dummies(df[\"Vendor\"])\n",
    "    df = pd.concat([df, vendor_series], axis=1)\n",
    "\n",
    "    # One-hot encode packet subtype\n",
    "    df[\"Subtype\"] = df[\"SubtypeNum\"].map(DATA_PKT_SUBTYPES)\n",
    "    subtype_series = pd.get_dummies(df[\"Subtype\"])\n",
    "    df = pd.concat([df, subtype_series], axis=1)    \n",
    "    \n",
    "    # Count packets for each device\n",
    "    device_counts = df[\"Name\"].value_counts()\n",
    "    print device_counts\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    randomforest = RandomForestClassifier(random_state=0, n_jobs=2)\n",
    "    rf_model = randomforest.fit(X_train, y_train)\n",
    "\n",
    "    preds = rf_model.predict(X_test)\n",
    "    score = rf_model.score(X_test, y_test)\n",
    "    \n",
    "#     print_confusion_matrix()\n",
    "    \n",
    "    time_elapsed = time.time() - time_start\n",
    "    return {'Score' : score, 'Time' : time_elapsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbors_classifier(X_train, y_train, X_test, y_test):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=5, n_jobs=2)\n",
    "    knn_model = knn.fit(X_train, y_train)\n",
    "    \n",
    "    preds = knn_model.predict(X_test)\n",
    "    score = knn_model.score(X_test, y_test)\n",
    "    \n",
    "#     print_confusion_matrix()\n",
    "    \n",
    "    time_elapsed = time.time() - time_start\n",
    "    return {'Score' : score, 'Time' : time_elapsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_classifier(X_train, y_train, X_test, y_test):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda_model = lda.fit(X_train, y_train)\n",
    "    \n",
    "    preds = lda_model.predict(X_test)\n",
    "    score = lda_model.score(X_test, y_test)\n",
    "    \n",
    "#     print_confusion_matrix()\n",
    "\n",
    "    time_elapsed = time.time() - time_start\n",
    "    return {'Score' : score, 'Time' : time_elapsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all_classify(df, features_list, y_list):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    # Divide df by train and test devices\n",
    "    df_test = df[df[\"Set\"]==\"test\"]\n",
    "    df_train = df[df[\"Set\"]==\"train\"]\n",
    "    \n",
    "    # Train using chosen features\n",
    "    X_train = df_train[features_list]\n",
    "    X_test = df_test[features_list]\n",
    "\n",
    "    for device_type in y_list:\n",
    "        # Set one device type as y\n",
    "        y_train = df_train[device_type]\n",
    "        y_test = df_test[device_type]\n",
    "\n",
    "        time_start_clf = time.time()\n",
    "\n",
    "        rf_clf = random_forest_classifier(X_train, y_train, X_test, y_test)\n",
    "        knn_clf = k_neighbors_classifier(X_train, y_train, X_test, y_test)\n",
    "        lda_clf = lda_classifier(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        time_elapsed_clf = time.time() - time_start_clf\n",
    "\n",
    "        print \"Device Type:\", device_type\n",
    "        print \"Random Forest Score:\", rf_clf['Score'], \"Time: \", rf_clf['Time']\n",
    "        print \"KNN Score:\", knn_clf['Score'], \"Time: \", knn_clf['Time']\n",
    "        print \"LDA Score:\", lda_clf['Score'], \"Time: \", lda_clf['Time']\n",
    "        print \"Total time (classifiers):\", time_elapsed_clf\n",
    "        print \"\"\n",
    "    \n",
    "    print \"Total time (one vs all_classify):\", time.time() - time_start\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_one_classify(df, features_list, y_list):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    # Get possible combinations for one vs one\n",
    "    combinations = [combination for combination in itertools.combinations(y_list, 2)]\n",
    "\n",
    "    for device_pair in combinations:\n",
    "        # Only use data with the two device types needed for one vs one classification\n",
    "        pos_device_type = device_pair[0]\n",
    "        neg_device_type = device_pair[1]\n",
    "        df_1v1 = df[(df[\"DeviceType\"]==pos_device_type) | (df[\"DeviceType\"]==neg_device_type)]\n",
    "\n",
    "        # Separate df into train and test sets\n",
    "        df_train = df_1v1[df_1v1[\"Set\"]==\"train\"]\n",
    "        df_test = df_1v1[df_1v1[\"Set\"]==\"test\"]\n",
    "        X_train = df_train[features_list]\n",
    "        X_test = df_test[features_list]\n",
    "        y_train = df_train[pos_device_type]\n",
    "        y_test = df_test[pos_device_type]\n",
    "        \n",
    "        time_start_clf = time.time()\n",
    "\n",
    "        rf_clf = random_forest_classifier(X_train, y_train, X_test, y_test)\n",
    "        knn_clf = k_neighbors_classifier(X_train, y_train, X_test, y_test)\n",
    "        lda_clf = lda_classifier(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        time_elapsed_clf = time.time() - time_start_clf\n",
    "\n",
    "        print \"Device Pair:\", device_pair\n",
    "        print \"Random Forest Score:\", rf_clf['Score'], \"Time: \", rf_clf['Time']\n",
    "        print \"KNN Score:\", knn_clf['Score'], \"Time: \", knn_clf['Time']\n",
    "        print \"LDA Score:\", lda_clf['Score'], \"Time: \", lda_clf['Time']\n",
    "        print \"Total time (classifiers):\", time_elapsed_clf\n",
    "        print \"\"\n",
    "    \n",
    "    print \"Total time (one vs one_classify):\", time.time() - time_start\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix():\n",
    "    return \"print_confusion_matrix goes here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old ./Source deleted\n",
      "Old ./Destination deleted\n",
      "Total number of packets processed:  1375941\n",
      "Total data processing time:  1538.946208\n",
      "Normalized total processing time per 25k packets:  27.9617041719\n",
      "Total capture file processing time:  151.765662193\n",
      "Normalized capture file processing time:  2.75748855135\n"
     ]
    }
   ],
   "source": [
    "# Main \n",
    "pcap_path = os.path.join(PCAP_DIR, 'master.cap')\n",
    "# feature_extractor(pcap_path)\n",
    "extract_packet_features(create_master=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini       104280\n",
      "Router     103593\n",
      "Dropcam     64568\n",
      "Kasa        23753\n",
      "Netcam3      4867\n",
      "Netcam1      4446\n",
      "Netcam2      4407\n",
      "Switch2      3046\n",
      "Switch1      2668\n",
      "Switch3      2634\n",
      "Insight      2556\n",
      "Switch4      2206\n",
      "Lifx2         627\n",
      "TpPlug        587\n",
      "Lifx1         540\n",
      "TpBulb        202\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = make_dataframe()\n",
    "\n",
    "# Limit to two device types\n",
    "# df = df[(df[\"DeviceType\"]!=\"bulb\") & (df[\"DeviceType\"]!=\"router\")]\n",
    "\n",
    "# Take out packets from router\n",
    "df = df[df[\"DeviceType\"]!=\"router\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train    189347\n",
      "test      32040\n",
      "Name: Set, dtype: int64\n",
      "0    192137\n",
      "1     29250\n",
      "Name: QoS_Data, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print df[\"DeviceType\"].value_counts()\n",
    "print df[\"Set\"].value_counts()\n",
    "print df[\"QoS_Data\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Time', u'PacketLength', u'Duration', u'SourceAddr', u'DestAddr',\n",
      "       u'SubtypeNum', u'DeviceType', u'Name', u'Set', u'bulb', u'camera',\n",
      "       u'plug', u'router', u'Vendor', u'Belkin', u'Dropcam', u'Lifi',\n",
      "       u'Netgear', u'Tp-link', u'Subtype', u'Data', u'QoS_Data', u'QoS_Null'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Use StratifiedShuffleSplit to create train and test sets\\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\\nX = df[[\\n        # Packet info\\n        \"PacketLength\", \"Duration\", \\n        \\n        # Vendor \\n        \"Belkin\", \"Dropcam\", \"Lifi\", \"Netgear\", \"Tp-link\",\\n    \\n        # 802.11 Data subtype\\n        \"Data\", \"QoS_Data\", \"QoS_Null\"]]\\ny = df[\"DeviceType\"]\\n\\nfor train_index, test_index in sss.split(X, y):\\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Use StratifiedShuffleSplit to create train and test sets\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "X = df[[\n",
    "        # Packet info\n",
    "        \"PacketLength\", \"Duration\", \n",
    "        \n",
    "        # Vendor \n",
    "        \"Belkin\", \"Dropcam\", \"Lifi\", \"Netgear\", \"Tp-link\",\n",
    "    \n",
    "        # 802.11 Data subtype\n",
    "        \"Data\", \"QoS_Data\", \"QoS_Null\"]]\n",
    "y = df[\"DeviceType\"]\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# y_train = df_train[\"bulb\"]\n",
    "# y_test = df_test[\"bulb\"]\n",
    "\n",
    "\n",
    "\n",
    "# print X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "# print y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Type: camera\n",
      "Random Forest Score: 0.14294631710362046 Time:  0.499722003937\n",
      "KNN Score: 0.6539637952559301 Time:  58.1517760754\n",
      "LDA Score: 0.6486579275905119 Time:  0.070200920105\n",
      "Total time (classifiers): 58.7218239307\n",
      "\n",
      "Device Type: bulb\n",
      "Random Forest Score: 0.997940074906367 Time:  0.538209199905\n",
      "KNN Score: 0.9979088639200999 Time:  58.4720609188\n",
      "LDA Score: 0.9933832709113608 Time:  0.0644340515137\n",
      "Total time (classifiers): 59.074794054\n",
      "\n",
      "Device Type: plug\n",
      "Random Forest Score: 0.14400749063670412 Time:  0.513722896576\n",
      "KNN Score: 0.6552434456928838 Time:  58.7210381031\n",
      "LDA Score: 0.16963171036204744 Time:  0.0652160644531\n",
      "Total time (classifiers): 59.3000509739\n",
      "\n",
      "Total time (one vs all_classify): 177.154328823\n",
      "\n",
      "Device Pair: ('camera', 'bulb')\n",
      "Random Forest Score: 0.9982220398673368 Time:  0.422652006149\n",
      "KNN Score: 0.9981194652442985 Time:  13.5969889164\n",
      "LDA Score: 0.9931958833384621 Time:  0.0260739326477\n",
      "Total time (classifiers): 14.0457799435\n",
      "\n",
      "Device Pair: ('camera', 'plug')\n",
      "Random Forest Score: 0.12698564288670297 Time:  0.524857997894\n",
      "KNN Score: 0.15378983223506193 Time:  58.2543129921\n",
      "LDA Score: 0.1533759908318212 Time:  0.0710427761078\n",
      "Total time (classifiers): 58.8502800465\n",
      "\n",
      "Device Pair: ('bulb', 'plug')\n",
      "Random Forest Score: 0.9815789473684211 Time:  0.375375986099\n",
      "KNN Score: 0.8251461988304094 Time:  15.7858338356\n",
      "LDA Score: 0.9447368421052632 Time:  0.0928809642792\n",
      "Total time (classifiers): 16.2541880608\n",
      "\n",
      "Total time (one vs one_classify): 89.38281703\n",
      "\n",
      "Total time (one vs one & one vs all classification): 266.551095963\n"
     ]
    }
   ],
   "source": [
    "# Run One vs All  and One vs One classification strategies\n",
    "features_list = [\n",
    "        # Packet info\n",
    "        \"PacketLength\", \"Duration\", \n",
    "        \n",
    "        # Vendor \n",
    "#         \"Belkin\", \"Dropcam\", \"Lifi\", \"Netgear\", \"Tp-link\",\n",
    "    \n",
    "        # 802.11 Data subtype\n",
    "        \"Data\", \"QoS_Data\", \"QoS_Null\"]\n",
    "\n",
    "y_list = [\"camera\", \"bulb\", \"plug\"]\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "one_vs_all_classify(df, features_list, y_list)\n",
    "one_vs_one_classify(df, features_list, y_list)\n",
    "\n",
    "print \"Total time (one vs one & one vs all classification):\", time.time() - time_start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
